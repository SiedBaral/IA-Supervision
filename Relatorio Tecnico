Relatório Técnico sobre o Programa de Classificação

Este relatório técnico tem como objetivo descrever em detalhes o funcionamento, os resultados e as métricas obtidas pelo programa de classificação desenvolvido. O programa utiliza quatro métodos de classificação supervisionada: KNN (K-Nearest Neighbors), Árvore de Decisão, SVM (Support Vector Machine) e Naive Bayes. O conjunto de dados utilizado é o "load_breast_cancer" do sklearn.datasets, que contém informações sobre diagnóstico de câncer de mama.

Funcionamento do Programa:
O programa foi desenvolvido em Python e utiliza a biblioteca scikit-learn para carregar o conjunto de dados, aplicar os métodos de classificação e avaliar o desempenho dos modelos. A seguir, descreveremos o fluxo de funcionamento do programa:
Carregamento do conjunto de dados: O programa carrega o conjunto de dados "load_breast_cancer" utilizando a função load_breast_cancer() do módulo datasets do scikit-learn.
Pré-processamento dos dados: Os dados são divididos em conjuntos de treinamento e teste utilizando a função train_test_split() do módulo model_selection do scikit-learn. Em seguida, os dados são padronizados utilizando a função StandardScaler() do módulo preprocessing do scikit-learn.
Treinamento dos modelos: Para cada método de classificação, o programa realiza o treinamento do modelo com os dados de treinamento utilizando os parâmetros escolhidos. Para o KNN, é variado o número de vizinhos (K) entre 1 e 455. Para a Árvore de Decisão, é variada a profundidade máxima da árvore entre 1 e 10. Para o SVM, é variada a margem de tolerância (C) entre 0.1 e 10. Para o Naive Bayes, não há variação de parâmetros.
Avaliação dos modelos: Após o treinamento, o programa avalia o desempenho de cada modelo utilizando métricas como acurácia, precisão, recall, matriz de confusão, F1-Score e curva ROC. Essas métricas são calculadas utilizando as funções disponíveis no módulo metrics do scikit-learn.
Geração do ranking: Por fim, o programa gera um ranking dos métodos de classificação com base na média geral das métricas de cada modelo. Essa média é calculada a partir das métricas obtidas em todas as variações dos parâmetros.
Resultados Obtidos:
Após executar o programa, os seguintes resultados foram obtidos para cada método de classificação:
KNN:

Melhor valor de vizinhos (K): 5
Acurácia: 0.9473684210526315
Precisão: 0.9577464788732394
Recall: 0.9577464788732394
Matriz de Confusão: [[40 3] [3 68]]
F1-Score: 0.9577464788732394
Árvore de Decisão:

Melhor valor de profundidade máxima: 5
Acurácia: 0.9385964912280702
Precisão: 0.9444444444444444
Recall: 0.9577464788732394
Matriz de Confusão: [[39 4] [3 68]]
F1-Score: 0.951048951048951
SVM:

Melhor valor de margem de tolerância (C): 0.1
Melhor valor de tipo de kernel: linear
Acurácia: 0.9824561403508771
Precisão: 0.9726027397260274
Recall: 1.0
Matriz de Confusão: [[41 2] [0 71]]
F1-Score: 0.9861111111111112
Naive Bayes:

Acurácia: 0.9649122807017544
Precisão: 0.958904109589041
Recall: 0.9859154929577465
Matriz de Confusão: [[40 3] [1 70]]
F1-Score: 0.9722222222222222
Análise dos Resultados:
Melhor método de classificação: Com base no ranking gerado, o método SVM obteve a maior média geral de todas as métricas, seguido pelo Naive Bayes, KNN e Árvore de Decisão. Portanto, o SVM foi o método que apresentou o melhor desempenho neste conjunto de dados específico.
Resultados esperados no mundo real: Os resultados obtidos no experimento podem ser considerados promissores para uso do modelo em prever/classificar amostras no mundo real. No entanto, é importante ressaltar que o desempenho do modelo pode variar dependendo do conjunto de dados e das características específicas do problema em questão.
Vantagens e desvantagens dos métodos de classificação:
KNN: Vantagens incluem simplicidade, fácil interpretação e capacidade de lidar com dados não lineares. Desvantagens incluem sensibilidade a dados ruidosos e dimensionalidade alta.
Árvore de Decisão: Vantagens incluem interpretabilidade, capacidade de lidar com dados não lineares e robustez a outliers. Desvantagens incluem tendência ao overfitting e pouca eficiência para grandes conjuntos de dados.
SVM: Vantagens incluem capacidade de lidar com dados de alta dimensionalidade, robustez a outliers e eficácia em problemas de classificação binária. Desvantagens incluem complexidade computacional e sensibilidade à escolha dos parâmetros e do kernel.
Naive Bayes: Vantagens incluem simplicidade, eficiência computacional e robustez a dados faltantes. Desvantagens incluem suposição de independência entre os atributos e baixo desempenho em dados com dependências complexas.
Impacto da parametrização nos resultados:
No KNN, a escolha do número de vizinhos (K) influenciou o desempenho do modelo. No experimento, o melhor valor de K foi encontrado como 5, resultando em uma acurácia, precisão e recall de aproximadamente 0.95.
Na Árvore de Decisão, a variação da profundidade máxima da árvore mostrou que o melhor valor foi encontrado em 5, resultando em uma acurácia, precisão e recall próximas de 0.94.
No SVM, a variação da margem de tolerância (C) e do tipo de kernel mostrou que o melhor valor foi encontrado em C=0.1 e kernel linear, resultando em uma acurácia próxima de 0.98, com alta precisão e recall.
No Naive Bayes, não houve variação de parâmetros, mas o modelo apresentou um desempenho consistente, com acurácia, precisão e recall em torno de 0.96.
Considerações Finais:
O programa de classificação desenvolvido demonstrou a aplicação de diferentes métodos de classificação em um conjunto de dados de diagnóstico de câncer de mama. Foram utilizados o KNN, Árvore de Decisão, SVM e Naive Bayes, sendo avaliados por diversas métricas, como acurácia, precisão, recall, matriz de confusão, F1-Score e curva ROC.
Com base nos resultados obtidos, o método SVM se destacou como o mais eficaz, apresentando a maior média geral de todas as métricas. No entanto, é importante ressaltar que a escolha do método de classificação mais adequado dependerá do conjunto de dados específico e das características do problema em questão.

O programa oferece flexibilidade para realizar variações de parâmetros nos métodos SVM e Árvore de Decisão, permitindo explorar diferentes configurações e otimizar o desempenho dos modelos.

Em resumo, o programa fornece uma abordagem abrangente e automatizada para a classificação de dados, permitindo a comparação e seleção de diferentes métodos com base em métricas de desempenho.
